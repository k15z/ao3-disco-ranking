{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AO3 Disco Ranking","text":"<p>This repository hosts the ranking models used by the AO3 Discovery Engine.</p>"},{"location":"#usage","title":"Usage","text":"<p>This library is designed to work with GuildAI which makes it easy to track and manage different model variants. For example, you can use guild to automatically tune the hyperparameters for  the first stage model:</p> <pre><code>guild run model_type=first \\\n    num_epochs='[2,5,10,100]' \\\n    output_dim='[64,128,256]' \\\n    max_hash_size='[10000,25000,50000]' \\\n    use_batch_norm='[True,False]' \\\n    --optimizer gp --maximize ncdg\n</code></pre> <p>Pre-trained models are stored as pickle files which can be loaded by the AO3 Disco server directly and used for inference.</p>"},{"location":"#design","title":"Design","text":"<p>At a high level, the ranking pipeline works at follows:</p> <ul> <li> <p>User submits a query (work + filters).</p> </li> <li> <p>First, we generate ~200 candidates.</p> <ul> <li>prematch. We find all works that are connected to the queried work (i.e. same author,  same fandom, same bookmarkers, etc.) and generate a score similar to something like PageRank.  If the queried work isn't very popular, this could fail to return any results (i.e. if there  are very few works in the fandom).</li> <li>first-stage. We use a neural network to map the queried work to a vector and find the 100 approximate nearest neighbors (after filtering). Note that this model doesn't consider any  interactions between the works - it independently maps every work to a vector.</li> </ul> </li> <li> <p>Then, we apply a second-stage model that contains more complex interaction features (i.e.     number of shared tags), etc. This model is used to generate the final ranking of the results.</p> </li> </ul> <p>This repository contains the code for training the first and second stage models.</p>"},{"location":"benchmark/","title":"Benchmark","text":"<p>This page will be periodically updated with the latest results.</p> Model Type Description NDCG deepsecond nn + interactions + listnet 0.9576 first nn + listnet ranking 0.9511 second xgboost + pairwise ranking loss 0.9399 second linear regression 0.9386 baseline random sort 0.7341"}]}